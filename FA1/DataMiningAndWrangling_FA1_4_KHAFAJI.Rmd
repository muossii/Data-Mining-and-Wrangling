---
title: "DataMiningAndWrangling_FA1_4_KHAFAJI"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

```

# Lesson 4: Data Wrangling

Unlike diamonds, data from the real world are not already built into an R package and are rarely are as clean. This lecture is about data wrangling, the art of getting your data into R in a useful form for visualization and modeling. These notes draw on Chapters 10-15 from R4DS.


We will cover:
• Data import using readr (getting the data into R)
• Tidy data (the most convenient data format to work with in R)
• Data tidying using tidyr (getting our data into a format amenable to analysis)
Let’s load the tidyverse:
library(tidyverse)


## Data Import
Data come in several different formats, e.g. comma-separated values (csv), tab-separated values (tsv), or
Excel files. To read files in csv or tsv formats, use read_csvand read_tsv, respectively. These are both part of the readr package, which is part of the tidyverse. These functions are very similar to each other. To read Excel files, use the read_excel function from the readxl package.
Let’s see how read_csv works. The simplest way of calling it is to specify just one argument (the location of
the file you’d like to read):

```{r import data}
heights = read_csv(file = "heights.csv")

```

```{r heights}

heights
```

Note that read_csv has automatically inferred the types of each column. It also made the assumption that the first line of the file are the column names. Sometimes, this is not the case. If column names are absent, you should specify the col_names argument either as FALSE or as a character vector of column names. Sometimes the files you’d like to read contain headers, i.e. one or more lines of metadata before the actual data starts. In this case, you can either skip a fixed number of lines (e.g. the first three) via skip = 3 or skip any lines starting with a certain character (e.g. #) via comment = "#". It’s a good idea to first open the data file before deciding how to import it.


Exercise: Import heights2.csv. 

cant find heights 2, will have to do with random csv instead:

```{r import ex}
cytof = read.csv(file = "cytof_one_experiment.csv")
```


## Tidy Data

“Happy families are all alike; every unhappy family is unhappy in its own way.” – Leo Tolstoy
“Tidy datasets are all alike, but every messy dataset is messy in its own way.” – Hadley Wickham
In this section, you will learn a consistent way to organise your data in R, an organisation called tidy data. Getting your data into this format requires some upfront work, but that work pays off in the long term. Once you have tidy data and the tidy tools provided by packages in the tidyverse, you will spend much less time munging data from one representation to another, allowing you to spend more time on the analytic questions at hand.
There are multiple ways to represent the same data

```{r data}
table1

```

```{r data2}
table2
```


```{r data3}
table3
```

```{r data4a}
table4a
```

```{r data4b}
table4b
```

These are all representations of the same underlying data, but they are not equally easy to use. One dataset,
the tidy dataset (table1), will be much easier to work with inside the tidyverse.
There are three interrelated rules which make a dataset tidy:
1. Each variable must have its own column.
2. Each observation must have its own row.
3. Each value must have its own cell.
The figure below shows the rules visually.

All the packages in the tidyverse are designed to work with tidy data. The tidyr package is designed to
get non-tidy data into tidy format.
Exercise: Using prose, describe how the variables and observations are organised in each of the sample tables.

## Pivoting

Once you get a non-tidy dataset, the first step is to figure out what the variables and observations are. Then,
you want to get the variables into columns and get observations into rows.
• If one variable is spread across multiple columns, you’ll need to pivot_longer.
• If one observation is scattered across multiple rows, you’ll need to pivot_wider.


### Longer

A common problem is a dataset where some of the column names are not names of variables, but values of a variable. Take table4a: the column names 1999 and 2000 represent values of the year variable, the values in the 1999 and 2000 columns represent values of the cases variable, and each row represents two observations, not one.

```{r data4a-2ND}
table4a
```


To tidy a dataset like this, we need to pivot the offending columns into a new pair of variables. To describe that operation we need three parameters:
• cols: The set of columns whose names are values, not variables. In this example, those are the columns 1999 and 2000.
• names_to: The name of the variable to move the column names to. Here it is year.
• values_to: The name of the variable to move the column values to. Here it’s cases.
Together those parameters generate the call to pivot_longer():

```{r pivot longer}
table4a %>%
pivot_longer(cols = c(`1999`, `2000`), names_to = "year", values_to = "cases")
```

Note that 1999 and 2000 are non-syntactic names (because they don’t start with a letter) so we have to surround them in backticks.
In the final result, the pivoted columns are dropped, and we get new year and cases columns. Otherwise, the relationships between the original variables are preserved. Visually, this is shown in the figure below.


Exercise: Use pivot_longer() to tidy table4b in a similar fashion. What is the difference between the code used to tidy table4a and table4b?

```{r excercise pivot longer}

table4b %>%
  pivot_longer(cols = c(`1999`, `2000`), names_to = "year", values_to = "population")
```

the values are cases in table4a, and population in table 4b.

### Wider

pivot_wider() is the opposite of pivot_longer(). You use it when an observation is scattered across
multiple rows. For example, take table2: an observation is a country in a year, but each observation is spread across two rows.

```{r table2}
table2
```

To tidy this up, we first analyse the representation in similar way to pivot_longer(). This time, however, we only need two parameters:
• The column to take variable names from. Here, it’s type.
• The column to take values from. Here it’s count.
Once we’ve figured that out, we can use pivot_wider().

```{r piv wider}
table2 %>%
pivot_wider(names_from = type, values_from = count)

```

Exercises:
1. Why does this code fail?

table4a %>%
pivot_longer(cols = c(1999, 2000), names_to = "year", values_to = "cases")
# Error: Can't subset columns that don't exist.
# Locations 1999 and 2000 don't exist.
# There are only 3 columns.


because 1999 and 2000 are treated as numeric column names.

Tidy the simple tibble below. Do you need to make it wider or longer? What are the variables?

```{r excer pivot}
dat = tribble(
~pregnant, ~male, ~female,
"yes", NA, 10,
"no", 20, 12
)

```
need to make it longer, and the variables are gender and pregnant.

## Joining

It’s rare that a data analysis involves only a single table of data. Typically you have many tables of data,
and you must combine them to answer the questions that you’re interested in. Collectively, multiple tables of
data are called relational data because it is the relations, not just the individual datasets, that are important.
Recall the tidy versions of table4a and table4b:

```{r }
tidy4a <- table4a %>%
pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "cases")
tidy4b <- table4b %>%
pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "population")
```

```{r}
tidy4a
```

```{r}
tidy4b
```

Joining two tables requires one or more key columns that are shared between the two tables. In this case, the key columns are country and year. There are several kinds of joins (see R4DS Chapter 13), but the most common is the left join (left_join() in dplyr). Given two tables x and y, left_join(x,y) tries to join y into x, keeping all rows in x (even if for some rows in x the key does not match any rows in y):

Let’s apply left_join() to tidy4a and tidy4b:

```{r}
left_join(x = tidy4a, y = tidy4b, by = c("country", "year"))

```


Exercise: Consider the two tibbles below. What is the key column? Without writing any code, can you
predict how many rows and columns left_join(x,y) and left_join(y,x) will have?

```{r}
x <- tribble(
~state, ~population,
"PA", 12.8,
"TX", 28.6,
"NY", 19.5
)

y <- tribble(
~state, ~capital,
"TX", "Austin",
"CA", "Sacramento",
"NY", "New York City",
"MI", "Lansing"
)
```

first is 3 rows and 3 columns, 2nd will have 4 rows and 3 columns.

## Separating

So far you’ve learned how to tidy table2 and table4, but not table3. table3 has a different problem: we
have one column (rate) that contains two variables (cases and population). To fix this problem, we’ll need
the separate() function.
separate() pulls apart one column into multiple columns, by splitting wherever a separator character
appears. Take table3:

```{r}

table3
```

The rate column contains both cases and population variables, and we need to split it into two variables. separate() takes the name of the column to separate, and the names of the columns to separate into, as shown below.


```{r}
table3 %>%
separate(rate, into = c("cases", "population"))
```

By default, separate() will split values wherever it sees a non-alphanumeric character (i.e. a character that isn’t a number or letter). For example, in the code above, separate() split the values of rate at the forward slash characters. If you wish to use a specific character to separate a column, you can pass the character to the sep argument of separate(). For example, we could rewrite the code above as:


```{r}
table3 %>%
separate(rate, into = c("cases", "population"), sep = "/")

```

Look carefully at the column types: you’ll notice that cases and population are character columns. This is the default behaviour in separate(): it leaves the type of the column as is. Here, however, it’s not very useful as those really are numbers. We can ask separate() to try and convert to better types using convert = TRUE:

```{r}
table3 %>%
separate(rate, into = c("cases", "population"), convert = TRUE)
```

You can also pass a vector of integers to sep. separate() will interpret the integers as positions to split at. Positive values start at 1 on the far-left of the strings; negative value start at -1 on the far-right of the strings. When using integers to separate strings, the length of sep should be one less than the number of names in
into. You can use this arrangement to separate the last two digits of each year. This make this data less tidy, but is useful in other cases.

```{r}
table3 %>%
separate(year, into = c("century", "year"), sep = 2)
```


## Missing Values

Missing values, marked with NA, are often present in real datasets. Consider the following simple dataset:

```{r}
stocks <- tibble(
year = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
qtr = c( 1, 2, 3, 4, 2, 3, 4),
return = c(1.88, 0.59, 0.35, NA, 0.92, 0.17, 2.66)
)
stocks
```


The NA means that the return for the fourth quarter of 2015 is missing. Changing the representation of a
dataset can create more missing values. For example, let’s pivot wider:

```{r}
stocks %>%
pivot_wider(names_from = year, values_from = return)

```

We see now that the return for the first quarter of 2016, which does not appear in the original dataset
(implicitly missing), becomes an NA (explicitly missing).
Usually it’s a good idea to treat missing values with care, e.g. by thinking about why those values might be
missing in the first place. The simplest approach to dealing with missing values in a dataset is to remove all
rows containing any missing values. This can be done via na.omit(). For example

```{r}
stocks %>%
na.omit()

```

## References:
• Data import cheat sheet
• tidyr cheat sheet
• R4DS Chapters 10-15





